In this data engineering ETL (Extract, Transform, Load) project, I harnessed the capabilities of various technologies to manage and analyze a dataset from Kaggle. 
The project commenced with data extraction from Kaggle's API, leveraging Python to access and retrieve the dataset efficiently. 
Following the extraction, the data was transformed in a Jupyter Notebook environment using Python. 
During this transformation phase, I cleaned, filtered, and manipulated the data to prepare it for analysis and storage. 
This included handling missing values, normalizing data formats, and deriving new metrics.

The transformed data was then loaded into the PostgreSQL database, structured appropriately to facilitate efficient querying and analysis. 
The final phase of the project involved solving complex SQL queries to extract valuable insights from the data. 
These queries were designed to address specific analytical requirements, showcasing the depth of information that could be gleaned from the well-organized dataset.
